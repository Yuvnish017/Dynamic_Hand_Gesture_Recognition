{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_model_CV_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4K5GC02-JVt"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.layers import Input, Conv3D, MaxPool3D, BatchNormalization, Dropout, Flatten, Dense, Activation\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HXjUocOAKFZ"
      },
      "source": [
        "X = []\n",
        "Y = []\n",
        "\n",
        "datadir = 'Dynamic_Hand_Gesture_Recognition/dataset'\n",
        "for classes in os.listdir(datadir):\n",
        "  path = os.path.join(datadir, classes)\n",
        "  for folder in os.listdir(path):\n",
        "    m = np.zeros(shape=(30, 128, 128, 1))\n",
        "    imgs = os.path.join(path, folder)\n",
        "    for i, img in enumerate(os.listdir(imgs)):\n",
        "      image = cv2.imread(os.path.join(imgs, img))\n",
        "      image = image/255.\n",
        "      m[i, :, :, :] = image\n",
        "    X.append(m)\n",
        "    Y.append(classes)\n",
        "\n",
        "print(len(X))\n",
        "print(len(Y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMwJ0Ht_C5zD"
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "Y = encoder.fit_transform(encoder)\n",
        "\n",
        "Y = np.array(Y)\n",
        "X = np.array(X)\n",
        "X = np.expand_dims(X, axis=-1)\n",
        "\n",
        "Y = to_categorical(Y)\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if_YaXtdHajO"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZjSIHLsS5QL"
      },
      "source": [
        "unique_train, count_train = np.unique(Y_train, return_counts=True)\n",
        "figure = plt.figure(figsize=(7, 7))\n",
        "sns.barplot(unique_train, count_train).set_title('Number of Images per category in Training Set')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uko220fYTRC8"
      },
      "source": [
        "unique_test, count_test = np.unique(Y_test, return_counts=True)\n",
        "figure = plt.figure(figsize=(7, 7))\n",
        "sns.barplot(unique_test, count_test).set_title('Number of Images per category in Test Set')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZj7MPwJHkkg"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape=(30, 128, 128, 1)))\n",
        "model.add(Conv3D(16, (5, 5, 5), activation='relu', kernel_initializer=glorot_uniform(seed=0), name='conv1'))\n",
        "model.add(MaxPool3D((2, 2, 2), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=glorot_uniform(seed=0), name='conv2'))\n",
        "model.add(MaxPool3D((2, 2, 2), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=glorot_uniform(seed=0), name='conv3'))\n",
        "model.add(MaxPool3D((2, 2, 2), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_initializer=glorot_uniform(seed=0), name='fc1'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu', kernel_initializer=glorot_uniform(seed=0), name='fc2'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(8, activation='softmax', kernel_initializer=glorot_uniform(seed=0), name='fc3'))\n",
        "\n",
        "opt = Adam()\n",
        "\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIN4QwPWJMMV"
      },
      "source": [
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/hand_gesture_recognition_v1.h5', monitor='val_loss', save_best_only=True, verbose=1, mode='min')\n",
        "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4)\n",
        "\n",
        "def step_decay(epoch):\n",
        "    initial_learning_rate = 0.001\n",
        "    dropEvery = 10\n",
        "    factor = 0.5\n",
        "    lr = initial_learning_rate*(factor**np.floor((1 + epoch)/dropEvery))\n",
        "    return float(lr)\n",
        "\n",
        "callbacks = [checkpoint, LR]\n",
        "# callbacks = [checkpoint, LearningRateScheduler(step_decay)]\n",
        "\n",
        "hist = model.fit(X_train, Y_train, batch_size=32, epoch=20, validation_data=(X_test, Y_test), callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-QgY_2lJSc-"
      },
      "source": [
        "figure1 = plt.figure(figsize=(10, 10))\n",
        "plt.plot(hist.history['accuracy'], label='Train_accuracy')\n",
        "plt.plot(hist.history['val_accuracy'], label='Test_accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "figure2 = plt.figure(figsize=(10, 10))\n",
        "plt.plot(hist.history['loss'], label='Train_loss')\n",
        "plt.plot(hist.history['val_loss'], label='Test_loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMGe_qv6J7vm"
      },
      "source": [
        "y_pred_test = model.predict(X_test)\n",
        "y_pred_test = np.argmax(y_pred_test, axis=1)\n",
        "Y_test_copy = np.argmax(Y_test, axis=1)\n",
        "print(classification_report(Y_test_copy, y_pred_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7FWKCowQq16"
      },
      "source": [
        "matrix = confusion_matrix(Y_test_copy, y_pred_test)\n",
        "figure = plt.figure(figsize=(7, 7))\n",
        "df = pd.DataFrame(matrix, index=[0, 1, 2, 3, 4, 5, 6, 7], columns=[0, 1, 2, 3, 4, 5, 6, 7])\n",
        "sns.heatmap(df, annot=True, fmg='d')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhlRatI3Tggf"
      },
      "source": [
        "def batch_generator(t, batch_number, batch_size):\n",
        "  d = {''}\n",
        "  batch_data = np.zeros(shape=(batch_size, 30, 128, 128, 1))\n",
        "  batch_label = np.zeros(shape=(batch_size, 8))\n",
        "  for folder in range(batch_size):\n",
        "    imgs = os.listdir('dataset/' + t[folder + (batch_number*batch_size)])\n",
        "    for i, img in enumerate(imgs):\n",
        "      image = cv2.imread(os.path.join('dataset/' + t[folder + (batch_number*batch_size)], img))\n",
        "      image = image/255.\n",
        "      batch_data[folder, i, :, :, :] = image\n",
        "    batch_label[folder, d[t[folder + (batch_number*batch_size)].split('_')[0]]] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlJYRiq7YSkl"
      },
      "source": [
        "def generator(folder_list, batch_size):\n",
        "  while True:\n",
        "    t = folder_list\n",
        "    num_batches = int(len(folder_list)/batch_size)\n",
        "    for batch in range(num_batches):\n",
        "      yield batch_generator(t, batch, batch_size)\n",
        "\n",
        "    if len(folder_list)%batch_size == 0:\n",
        "      batch_size = len(folder_list)%batch_size\n",
        "      yield batch_generator(t, batch, batch_size) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTpw4wy4THgJ"
      },
      "source": [
        "folder_names = os.listdir('dataset')\n",
        "folder_names = np.random.permutation(folder_names)\n",
        "\n",
        "train_folders = folder_names[:0.8*len(folder_names)]\n",
        "test_folders = folder_names[0.8*len(folder_names):]\n",
        "\n",
        "train_generator = generator(train_folders, 32)\n",
        "test_generator = generator(test_folders, 32)\n",
        "\n",
        "number_of_train_sequences = 0.8*len(folder_names)\n",
        "number_of_test_sequences = 0.2*len(folder_names)\n",
        "\n",
        "if (number_of_train_sequences%32) == 0:\n",
        "    steps_per_epoch = int(number_of_train_sequences/32)\n",
        "else:\n",
        "    steps_per_epoch = (number_of_train_sequences//32) + 1\n",
        "\n",
        "if (number_of_test_sequences%32) == 0:\n",
        "    validation_steps = int(number_of_test_sequences/32)\n",
        "else:\n",
        "    validation_steps = (number_of_test_sequences//32) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-TUOm6fU3Tk"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape=(30, 128, 128, 1)))\n",
        "model.add(Conv3D(16, (5, 5, 5), activation='relu', kernel_initializer=glorot_uniform(seed=0), name='conv1'))\n",
        "model.add(MaxPool3D((2, 2, 2), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=glorot_uniform(seed=0), name='conv2'))\n",
        "model.add(MaxPool3D((2, 2, 2), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=glorot_uniform(seed=0), name='conv3'))\n",
        "model.add(MaxPool3D((2, 2, 2), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_initializer=glorot_uniform(seed=0), name='fc1'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu', kernel_initializer=glorot_uniform(seed=0), name='fc2'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(8, activation='softmax', kernel_initializer=glorot_uniform(seed=0), name='fc3'))\n",
        "\n",
        "opt = Adam()\n",
        "\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBZuyYy-U-aY"
      },
      "source": [
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/hand_gesture_recognition_v1.h5', monitor='val_loss', save_best_only=True, verbose=1, mode='min')\n",
        "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4)\n",
        "\n",
        "def step_decay(epoch):\n",
        "    initial_learning_rate = 0.001\n",
        "    dropEvery = 10\n",
        "    factor = 0.5\n",
        "    lr = initial_learning_rate*(factor**np.floor((1 + epoch)/dropEvery))\n",
        "    return float(lr)\n",
        "\n",
        "callbacks = [checkpoint, LR]\n",
        "# callbacks = [checkpoint, LearningRateScheduler(step_decay)]\n",
        "\n",
        "hist = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, \n",
        "                           epochs=num_epochs, verbose=1, callbacks=callbacks,\n",
        "                           validation_data=val_generator, \n",
        "                           validation_steps=validation_steps,\n",
        "                           class_weight=None, workers=1, initial_epoch=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AK0PFNRVQMK"
      },
      "source": [
        "figure1 = plt.figure(figsize=(10, 10))\n",
        "plt.plot(hist.history['accuracy'], label='Train_accuracy')\n",
        "plt.plot(hist.history['val_accuracy'], label='Test_accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "figure2 = plt.figure(figsize=(10, 10))\n",
        "plt.plot(hist.history['loss'], label='Train_loss')\n",
        "plt.plot(hist.history['val_loss'], label='Test_loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}